# ğŸš€ Guide de DÃ©ploiement Streamlit - IA'ctualitÃ©s

## ğŸ“‹ Vue d'ensemble

Streamlit Cloud est la solution la plus simple pour dÃ©ployer rapidement votre application IA'ctualitÃ©s. IdÃ©al pour les prototypes et les applications avec un trafic modÃ©rÃ©.

## ğŸ—ï¸ Architecture Streamlit

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Cloud                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Frontend      â”‚  â”‚   Backend       â”‚  â”‚   Database   â”‚ â”‚
â”‚  â”‚   (Streamlit)   â”‚â—„â”€â”¤   (Python)      â”‚â—„â”€â”¤   (SQLite)   â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   External      â”‚
                       â”‚   AI Services   â”‚
                       â”‚   (Bedrock,     â”‚
                       â”‚    Azure)       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Conversion vers Streamlit

### 1. CrÃ©ation de l'Application Streamlit

```python
# streamlit_app.py
import streamlit as st
import requests
import json
from typing import List, Dict

# Configuration de la page
st.set_page_config(
    page_title="IA'ctualitÃ©s - Comparateur de ModÃ¨les LLM",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Variables d'environnement
BEDROCK_ENDPOINT = st.secrets.get("BEDROCK_ENDPOINT", "http://localhost:8000")
AZURE_OPENAI_KEY = st.secrets.get("AZURE_OPENAI_KEY")
AZURE_OPENAI_ENDPOINT = st.secrets.get("AZURE_OPENAI_ENDPOINT")

# ModÃ¨les disponibles
AVAILABLE_MODELS = [
    {"name": "Claude 3 Sonnet", "provider": "bedrock", "cost_per_1k": 0.003},
    {"name": "Claude 3 Haiku", "provider": "bedrock", "cost_per_1k": 0.00025},
    {"name": "Claude 3.7 Sonnet", "provider": "bedrock", "cost_per_1k": 0.003},
    {"name": "GPT-4o (Azure)", "provider": "azure", "cost_per_1k": 0.005},
    {"name": "GPT-4o Mini (Azure)", "provider": "azure", "cost_per_1k": 0.00015},
    {"name": "Mixtral 8x7B Instruct", "provider": "bedrock", "cost_per_1k": 0.00024},
    {"name": "Mistra 8x7B Instruct", "provider": "bedrock", "cost_per_1k": 0.00014},
    {"name": "Pixtral Large", "provider": "bedrock", "cost_per_1k": 0.00024}
]

def query_model(model_name: str, prompt: str) -> Dict:
    """Interroge un modÃ¨le LLM"""
    try:
        # Logique d'interrogation des modÃ¨les
        if "Azure" in model_name:
            # Appel Azure OpenAI
            pass
        else:
            # Appel Bedrock
            pass
        
        return {
            "response": "RÃ©ponse du modÃ¨le",
            "cost": 0.001,
            "tokens": 150
        }
    except Exception as e:
        return {"error": str(e)}

def main():
    st.title("ğŸ¤– IA'ctualitÃ©s - Comparateur de ModÃ¨les LLM")
    st.markdown("Comparez les rÃ©ponses de diffÃ©rents modÃ¨les d'intelligence artificielle")
    
    # Sidebar pour la sÃ©lection des modÃ¨les
    with st.sidebar:
        st.header("ğŸ¯ SÃ©lection des ModÃ¨les")
        st.info("SÃ©lectionnez jusqu'Ã  3 modÃ¨les maximum")
        
        selected_models = []
        for model in AVAILABLE_MODELS:
            if st.checkbox(f"{model['name']} ({model['provider']})", key=model['name']):
                if len(selected_models) < 3:
                    selected_models.append(model['name'])
                else:
                    st.warning("âš ï¸ Limite de 3 modÃ¨les atteinte")
                    break
        
        st.metric("ModÃ¨les sÃ©lectionnÃ©s", f"{len(selected_models)}/3")
    
    # Zone de saisie de question
    question = st.text_area(
        "ğŸ’­ Posez votre question :",
        placeholder="Ex: Expliquez la thÃ©orie de la relativitÃ© en termes simples...",
        height=100
    )
    
    # Bouton de comparaison
    if st.button("ğŸš€ Comparer les ModÃ¨les", type="primary", disabled=len(selected_models) == 0):
        if not question.strip():
            st.error("Veuillez saisir une question")
            return
        
        # Affichage des rÃ©sultats
        with st.spinner("ğŸ”„ Analyse en cours..."):
            results = []
            for model_name in selected_models:
                with st.expander(f"ğŸ“Š RÃ©sultats - {model_name}", expanded=True):
                    result = query_model(model_name, question)
                    
                    if "error" in result:
                        st.error(f"âŒ Erreur: {result['error']}")
                    else:
                        st.markdown("### RÃ©ponse :")
                        st.markdown(result["response"])
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("CoÃ»t", f"${result['cost']:.4f}")
                        with col2:
                            st.metric("Tokens", result['tokens'])
                        with col3:
                            st.metric("ModÃ¨le", model_name)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸ¤– IA'ctualitÃ©s - Comparateur de ModÃ¨les LLM</p>
        <p>PropulsÃ© par AWS Bedrock et Azure OpenAI</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
```

### 2. Configuration des DÃ©pendances

```txt
# requirements.txt
streamlit>=1.28.0
requests>=2.31.0
boto3>=1.34.0
openai>=1.3.0
python-dotenv>=1.0.0
pandas>=2.0.0
plotly>=5.17.0
```

### 3. Configuration Streamlit

```toml
# .streamlit/config.toml
[theme]
primaryColor = "#1a237e"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#262730"
font = "sans serif"

[server]
maxUploadSize = 200
enableXsrfProtection = false
enableCORS = false

[browser]
gatherUsageStats = false
```

## ğŸš€ DÃ©ploiement sur Streamlit Cloud

### 1. PrÃ©paration du Repository

```bash
# Structure du projet
iactualities-streamlit/
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

### 2. Configuration des Secrets

Dans Streamlit Cloud, ajoutez ces variables d'environnement :

```json
{
  "BEDROCK_ACCESS_KEY": "votre_clÃ©_aws",
  "BEDROCK_SECRET_KEY": "votre_secret_aws",
  "BEDROCK_REGION": "us-east-1",
  "AZURE_OPENAI_KEY": "votre_clÃ©_azure",
  "AZURE_OPENAI_ENDPOINT": "votre_endpoint_azure"
}
```

### 3. DÃ©ploiement

1. **Connectez votre repository GitHub** Ã  Streamlit Cloud
2. **SÃ©lectionnez le fichier** `streamlit_app.py`
3. **Configurez les variables d'environnement**
4. **DÃ©ployez** en un clic !

## ğŸ’° CoÃ»ts Streamlit Cloud

- **Gratuit** : 3 applications, 1GB RAM, 1 CPU
- **Pro** : $10/mois - Applications illimitÃ©es, 8GB RAM, 4 CPU
- **Enterprise** : Sur devis

## ğŸ”’ SÃ©curitÃ©

- **HTTPS** automatique
- **Isolation** des applications
- **Variables d'environnement** sÃ©curisÃ©es
- **Authentification** optionnelle

## ğŸ“Š Monitoring

- **Logs** en temps rÃ©el
- **MÃ©triques** de performance
- **Alertes** automatiques
- **Analytics** d'utilisation

## ğŸ¯ Avantages de cette Solution

1. **SimplicitÃ©** : DÃ©ploiement en 5 minutes
2. **Gratuit** : Pour commencer
3. **RapiditÃ©** : Pas de configuration complexe
4. **IntÃ©gration** : Python natif
5. **CommunautÃ©** : Support actif
6. **ScalabilitÃ©** : GÃ©rÃ©e par Streamlit

## âš ï¸ Points d'Attention

- **Limitations** : 1GB RAM en gratuit
- **Performance** : Moins optimisÃ© que les solutions natives
- **Personnalisation** : Interface limitÃ©e
- **Vendor Lock-in** : DÃ©pendance Ã  Streamlit

## ğŸ”§ Script de DÃ©ploiement Automatique

```yaml
# .github/workflows/deploy-streamlit.yml
name: Deploy to Streamlit Cloud
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy to Streamlit Cloud
        run: |
          echo "ğŸš€ DÃ©ploiement automatique vers Streamlit Cloud"
          echo "âœ… Le dÃ©ploiement se fait automatiquement via l'intÃ©gration GitHub"
```

## ğŸ“ˆ Optimisations RecommandÃ©es

1. **Cache** : Utilisez `@st.cache_data` pour les requÃªtes coÃ»teuses
2. **Session State** : GÃ©rer l'Ã©tat entre les interactions
3. **Lazy Loading** : Charger les donnÃ©es Ã  la demande
4. **Error Handling** : Gestion robuste des erreurs
5. **Rate Limiting** : Limiter les appels API 